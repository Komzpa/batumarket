"""Render static HTML pages from JSON lots using Jinja2.

Each ``*.json`` file under ``data/lots`` may contain several lots so we assign
a unique ``_page_id`` to every entry.  Templates live in ``templates/`` and the
output is written to ``data/views`` keeping the directory layout intact.  The
script also loads embeddings from ``data/embeddings`` if present to find similar
lots based on cosine similarity.  ``data/ontology/fields.json`` is consulted to
display table columns in a stable order.
"""

import os
from pathlib import Path
import shutil
import subprocess
from datetime import datetime, timedelta, timezone

from jinja2 import Environment, FileSystemLoader
import gettext
from serde_utils import load_json
from lot_io import (
    read_lots,
    get_seller,
    get_timestamp,
    iter_lot_files,
)
from similar_utils import (
    SIMILAR_DIR,
    _load_embeddings,
    _format_vector,
    _load_similar,
    _save_similar,
    _prune_similar,
    _calc_similar_nn,
    _cos_sim,
)

from config_utils import load_config
from log_utils import get_logger, install_excepthook
from moderation import should_skip_message, should_skip_lot
from post_io import read_post, raw_post_path, RAW_DIR
from caption_io import read_caption
from price_utils import (
    train_price_regression,
    predict_price,
    currency_rates,
    guess_currency,
)

log = get_logger().bind(script=__file__)
install_excepthook(log)

LOTS_DIR = Path("data/lots")
VIEWS_DIR = Path("data/views")
TEMPLATES = Path("templates")
EMBED_DIR = Path("data/embeddings")
ONTOLOGY = Path("data/ontology/fields.json")
LOCALE_DIR = Path("locale")
MEDIA_DIR = Path("data/media")



def _load_ontology() -> list[str]:
    if not ONTOLOGY.exists():
        return []
    data = load_json(ONTOLOGY)
    if not isinstance(data, dict):
        log.error("Bad ontology", path=str(ONTOLOGY))
        return []
    fields = sorted(data.keys())
    log.info("Loaded ontology", count=len(fields))
    return fields


def _compile_locale(lang: str) -> None:
    po = LOCALE_DIR / lang / 'LC_MESSAGES' / 'messages.po'
    mo = po.with_suffix('.mo')
    if not po.exists():
        return
    if not mo.exists() or po.stat().st_mtime > mo.stat().st_mtime:
        try:
            subprocess.run(['msgfmt', str(po), '-o', str(mo)], check=True)
            log.debug('Compiled translation', lang=lang)
        except Exception:
            log.exception('Failed to compile translation', lang=lang)


def _env_for_lang(lang: str) -> Environment:
    _compile_locale(lang)
    env = Environment(
        loader=FileSystemLoader(str(TEMPLATES)),
        extensions=['jinja2.ext.i18n'],
    )
    mo = LOCALE_DIR / lang / 'LC_MESSAGES' / 'messages.mo'
    try:
        trans = gettext.GNUTranslations(mo.open('rb'))
    except Exception:
        trans = gettext.NullTranslations()
    # Translation files use ``%(name)s`` placeholders generated by gettext,
    # so stick to the classic percent formatting style.  ``newstyle`` would
    # expect ``{name}`` placeholders which our .po files don't contain and
    # would trigger ``ValueError`` when rendering.
    env.install_gettext_translations(trans, newstyle=False)
    return env






def _iter_lots() -> list[dict]:
    """Return all lots ready for rendering."""
    lots = []
    # ``iter_lot_files`` keeps file ordering consistent with ``pending_embed.py``
    # so both scripts see the same data in the same order.
    for path in iter_lot_files(LOTS_DIR):
        data = read_lots(path)
        if not data:
            continue
        rel = path.relative_to(LOTS_DIR).with_suffix("")
        base = rel.name
        prefix = rel.parent
        for i, lot in enumerate(data):
            src = lot.get("source:path")
            meta: dict[str, str] | None = None
            text = ""
            if src:
                raw_path = raw_post_path(src, RAW_DIR)
                meta, text = read_post(raw_path)
                if should_skip_message(meta, text):
                    log.info(
                        "Skipping lot",
                        file=str(path),
                        reason="moderation",
                        source=str(src),
                    )
                    continue
            if should_skip_lot(lot):
                log.info(
                    "Skipping lot",
                    file=str(path),
                    reason="moderation",
                    source=str(src) if src else None,
                )
                continue
            lot["_file"] = path
            lot["_id"] = str(prefix / f"{base}-{i}") if prefix.parts else f"{base}-{i}"
            lots.append(lot)
    log.info("Loaded lots", count=len(lots))
    return lots


def _copy_images(lots: list[dict]) -> None:
    media_dst = VIEWS_DIR / "media"
    if media_dst.exists():
        shutil.rmtree(media_dst)
    for lot in lots:
        for rel in lot.get("files", []):
            src = MEDIA_DIR / rel
            if not src.exists():
                continue
            dst = media_dst / rel
            dst.parent.mkdir(parents=True, exist_ok=True)
            shutil.copy2(src, dst)


def build_page(
    lot: dict,
    similar: list[dict],
    more_user: list[dict],
    fields: list[str],
    langs: list[str],
    embedding: list[float] | None,
    lookup: dict[str, dict],
) -> None:
    """Render ``lot`` into separate HTML files for every language."""
    for lang in langs:
        env = _env_for_lang(lang)
        images = []
        for rel in lot.get("files", []):
            p = MEDIA_DIR / rel
            caption = read_caption(p, lang)
            images.append({"path": rel, "caption": caption})

        # Drop internal helper fields that are meaningless to end users.
        attrs = {
            k: v
            for k, v in lot.items()
            if k not in {"files", "ai_price"}
            and not k.startswith("title_")
            and not k.startswith("description_")
            and not k.startswith("source:")
            and not k.startswith("_")
            and v not in ("", None)
        }
        if "price" not in attrs and lot.get("ai_price") is not None:
            attrs["price"] = lot["ai_price"]
        sorted_attrs = {k: attrs[k] for k in fields if k in attrs}
        for k in attrs:
            if k not in sorted_attrs:
                sorted_attrs[k] = attrs[k]

        ts = sorted_attrs.get("timestamp")
        dt = get_timestamp(lot)
        if ts and dt is None:
            del sorted_attrs["timestamp"]

        # Show the original message text for context if available.
        orig_text = ""
        src = lot.get("source:path")
        if src:
            _, orig_text = read_post(raw_post_path(src, RAW_DIR))

        chat = lot.get("source:chat")
        mid = lot.get("source:message_id")
        tg_link = f"https://t.me/{chat}/{mid}" if chat and mid else ""

        template = env.get_template("lot.html")
        out = VIEWS_DIR / f"{lot['_id']}_{lang}.html"
        out.parent.mkdir(parents=True, exist_ok=True)

        page_similar = []
        for item in similar:
            other = lookup.get(item["id"], {})
            title = (
                other.get(f"title_{lang}")
                or other.get("title_en")
                or next(
                    (other.get(f"title_{l}") for l in langs if other.get(f"title_{l}")),
                    item["id"],
                )
            )
            files = other.get("files") or []
            thumb = files[0] if files else ""
            page_similar.append(
                {
                    "link": os.path.relpath(
                        VIEWS_DIR / f"{item['id']}_{lang}.html",
                        out.parent,
                    ),
                    "title": title,
                    "thumb": thumb,
                }
            )
        page_user = []
        for item in more_user:
            other = lookup.get(item["id"], {})
            title = (
                other.get(f"title_{lang}")
                or other.get("title_en")
                or next(
                    (other.get(f"title_{l}") for l in langs if other.get(f"title_{l}")),
                    item["id"],
                )
            )
            files = other.get("files") or []
            thumb = files[0] if files else ""
            page_user.append(
                {
                    "link": os.path.relpath(
                        VIEWS_DIR / f"{item['id']}_{lang}.html",
                        out.parent,
                    ),
                    "title": title,
                    "thumb": thumb,
                }
            )
        static_prefix = os.path.relpath(VIEWS_DIR / "static", out.parent)
        media_prefix = os.path.relpath(VIEWS_DIR / "media", out.parent)
        home_link = os.path.relpath(VIEWS_DIR / f"index_{lang}.html", out.parent)
        page_basename = Path(lot['_id']).name
        breadcrumbs = [{"title": "Home", "link": home_link}]
        deal = lot.get("market:deal")
        if isinstance(deal, list):
            deal = deal[0] if deal else None
        if deal:
            cat_link = os.path.relpath(
                VIEWS_DIR / "deal" / f"{deal}_{lang}.html",
                out.parent,
            )
            breadcrumbs.append({"title": deal, "link": cat_link})
        breadcrumbs.append({"title": lot.get(f"title_{lang}") or lot['_id'], "link": None})
        embed_str = _format_vector(embedding)
        out.write_text(
            template.render(
                title=lot.get(f"title_{lang}", "Lot"),
                lot=lot,
                images=images,
                attrs=sorted_attrs,
                orig_text=orig_text,
                description=lot.get(f"description_{lang}", ""),
                tg_link=tg_link,
                similar=page_similar,
                more_user=page_user,
                langs=langs,
                current_lang=lang,
                page_basename=page_basename,
                static_prefix=static_prefix,
                media_prefix=media_prefix,
                breadcrumbs=breadcrumbs,
                embed=embed_str,
            )
        )
        log.debug("Wrote", path=str(out))


def main() -> None:
    log.info("Building site")
    cfg = load_config()
    langs = getattr(cfg, "LANGS", ["en"])
    keep_days = getattr(cfg, "KEEP_DAYS", 7)
    envs = {lang: _env_for_lang(lang) for lang in langs}
    VIEWS_DIR.mkdir(parents=True, exist_ok=True)

    # Copy CSS and JS so the generated pages are standalone
    static_src = TEMPLATES / "static"
    static_dst = VIEWS_DIR / "static"
    if static_src.exists():
        if static_dst.exists():
            shutil.rmtree(static_dst)
        shutil.copytree(static_src, static_dst)
        log.debug("Copied static assets", src=str(static_src), dst=str(static_dst))

    log.debug("Loading ontology")
    fields = _load_ontology()
    log.debug("Loading embeddings")
    embeddings = _load_embeddings()
    log.debug("Loading lots")
    lots = _iter_lots()
    _copy_images(lots)
    log.debug("Loading similar cache")
    sim_map = _load_similar()

    # Clean up mismatched data before working on embeddings.
    lot_keys = {lot["_id"] for lot in lots}
    emb_keys = set(embeddings)
    extra_embs = emb_keys - lot_keys
    if extra_embs:
        for key in extra_embs:
            embeddings.pop(key, None)
        log.debug("Dropped embeddings without lots", count=len(extra_embs))
    missing_embs = lot_keys - emb_keys
    if missing_embs:
        lots = [lot for lot in lots if lot["_id"] not in missing_embs]
        log.debug("Dropped lots without embeddings", count=len(missing_embs))

    # Map each lot id to its embedding vector if available.
    id_to_vec = {lot["_id"]: embeddings.get(lot["_id"]) for lot in lots}
    lookup = {lot["_id"]: lot for lot in lots}

    # Train regression model to predict prices from embeddings.  ``rates``
    # capture implicit exchange multipliers learnt from the training data.
    log.debug("Training price model")
    price_model, currency_map = train_price_regression(lots, id_to_vec)
    rates = currency_rates(price_model, currency_map) if price_model else {}
    if rates:
        log.info("Regressed currency rates", rates=rates)

    log.info("Computing similar lots", count=len(lots))

    _prune_similar(sim_map, lot_keys)

    new_ids = [i for i in lot_keys if i not in sim_map]
    vec_ids = [i for i in lot_keys if id_to_vec.get(i)]

    _calc_similar_nn(sim_map, new_ids, vec_ids, id_to_vec)


    # Collect lots by Telegram user for "more by this user" section.
    user_map: dict[str, list[dict]] = {}
    for lot in lots:
        user = (
            lot.get("contact:telegram")
            or lot.get("source:author:telegram")
            or lot.get("source:author:name")
        )
        if isinstance(user, list):
            log.debug("Multiple telegram users", id=lot.get("_id"), value=user)
            user = user[0] if user else None
        if user is not None:
            user_map.setdefault(str(user), []).append(lot)

    more_user_map: dict[str, list[dict]] = {}
    for user, user_lots in user_map.items():
        for lot in user_lots:
            others = [o for o in user_lots if o is not lot]
            scores = []
            vec = id_to_vec.get(lot["_id"])
            for other in others:
                ov = id_to_vec.get(other["_id"])
                if vec and ov:
                    scores.append((_cos_sim(vec, ov), other))
                else:
                    scores.append((0.0, other))
            scores.sort(key=lambda x: x[0], reverse=True)
            items = [{"id": other["_id"]} for _, other in scores[:20]]
            more_user_map[lot["_id"]] = items

    for lot in lots:
        vec = id_to_vec.get(lot["_id"])
        pred_usd = predict_price(price_model, currency_map, vec, "USD")
        if pred_usd is not None:
            # Store predicted USD amount for template fallback
            lot["ai_price"] = round(pred_usd, 2)
        if lot.get("price") is not None and lot.get("price:currency") is None:
            # Attempt to guess missing currency using regressed rates
            try:
                price_val = float(lot["price"])
            except Exception:
                price_val = None
            if price_val and pred_usd:
                guessed = guess_currency(rates, price_val, pred_usd)
                if guessed:
                    lot["price:currency"] = guessed

    # ``datetime.utcnow`` returns a naive object which breaks comparisons with
    # timezone-aware timestamps coming from lots.  Normalize everything to UTC.
    now = datetime.now(timezone.utc)
    recent_cutoff = now - timedelta(days=keep_days)
    recent = []
    categories: dict[str, list[dict]] = {}
    category_stats: dict[str, dict] = {}
    for lot in lots:
        dt = get_timestamp(lot)
        deal = lot.get("market:deal", "misc")
        if not isinstance(deal, str):
            log.debug("Non-string deal", id=lot.get("_id"), value=deal)
            if isinstance(deal, list) and deal:
                deal = deal[0]
            else:
                deal = str(deal)
        categories.setdefault(deal, []).append(lot)
        stat = category_stats.setdefault(deal, {"recent": 0, "users": set()})
        user = lot.get("contact:telegram")
        if isinstance(user, list):
            log.debug("Multiple telegram users", id=lot.get("_id"), value=user)
            user = user[0] if user else None
        if user:
            stat["users"].add(str(user))
        if dt and dt >= recent_cutoff:
            titles = {lang: lot.get(f"title_{lang}") for lang in langs}
            seller = get_seller(lot)
            stat["recent"] += 1
            recent.append(
                {
                    "id": lot["_id"],
                    "titles": titles,
                    "dt": dt,
                    "price": lot.get("price") or lot.get("ai_price"),
                    "seller": seller,
                }
            )

    for lot in lots:
        log.debug("Rendering", id=lot["_id"])
        build_page(
            lot,
            sim_map.get(lot["_id"], []),
            more_user_map.get(lot["_id"], []),
            fields,
            langs,
            id_to_vec.get(lot["_id"]),
            lookup,
        )

    log.debug("Writing category pages")
    cat_tpls = {lang: envs[lang].get_template("category.html") for lang in langs}
    cat_dir = VIEWS_DIR / "deal"
    cat_dir.mkdir(parents=True, exist_ok=True)
    for deal, lot_list in categories.items():
        lot_list_sorted = sorted(
            lot_list,
            key=lambda x: get_timestamp(x) or datetime.min,
            reverse=True,
        )
        for lang in langs:
            items_lang = []
            for lot in lot_list_sorted:
                title = lot.get(f"title_{lang}") or next(
                    (lot.get(f"title_{l}") for l in langs if lot.get(f"title_{l}")),
                    lot.get("_id"),
                )
                seller = get_seller(lot)
                dt = get_timestamp(lot)
                items_lang.append(
                    {
                        "link": os.path.relpath(
                            VIEWS_DIR / f"{lot['_id']}_{lang}.html",
                            cat_dir,
                        ),
                        "title": title,
                        "dt": dt,
                        "price": lot.get("price") or lot.get("ai_price"),
                        "seller": seller,
                        "id": lot["_id"],
                        "embed": _format_vector(id_to_vec.get(lot["_id"])),
                    }
                )
            out = cat_dir / f"{deal}_{lang}.html"
            breadcrumbs = [
                {"title": "Home", "link": os.path.relpath(VIEWS_DIR / f"index_{lang}.html", cat_dir)},
                {"title": deal, "link": None},
            ]
            out.write_text(
                cat_tpls[lang].render(
                    deal=deal,
                    items=items_lang,
                    langs=langs,
                    current_lang=lang,
                    page_basename=deal,
                    title=deal,
                    static_prefix=os.path.relpath(VIEWS_DIR / "static", cat_dir),
                    breadcrumbs=breadcrumbs,
                )
            )
            log.debug("Wrote", path=str(out))

    recent.sort(key=lambda x: x.get("dt") or datetime.min.replace(tzinfo=timezone.utc), reverse=True)

    log.debug("Writing index pages")
    index_tpls = {lang: envs[lang].get_template("index.html") for lang in langs}
    for lang in langs:
        cats_lang = []
        for deal, stat in category_stats.items():
            cats_lang.append(
                {
                    "link": os.path.relpath(cat_dir / f"{deal}_{lang}.html", VIEWS_DIR),
                    "deal": deal,
                    "recent": stat["recent"],
                    "users": len(stat["users"]),
                }
            )
        out = VIEWS_DIR / f"index_{lang}.html"
        breadcrumbs = [{"title": "Home", "link": f"index_{lang}.html"}]
        out.write_text(
            index_tpls[lang].render(
                categories=cats_lang,
                langs=langs,
                current_lang=lang,
                page_basename="index",
                title="Index",
                static_prefix=os.path.relpath(VIEWS_DIR / "static", VIEWS_DIR),
                breadcrumbs=breadcrumbs,
                keep_days=keep_days,
            )
        )
        log.debug("Wrote", path=str(out))
    if langs:
        default = VIEWS_DIR / "index.html"
        src = VIEWS_DIR / f"index_{langs[0]}.html"
        default.write_text(src.read_text())
        log.debug("Wrote", path=str(default))
    _save_similar(sim_map)
    log.info("Site build complete")


if __name__ == "__main__":
    main()
