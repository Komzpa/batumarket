"""Render static HTML pages from JSON lots using Jinja2.

Each ``*.json`` file under ``data/lots`` may contain several lots so we assign
a unique ``_page_id`` to every entry.  Templates live in ``templates/`` and the
output is written to ``data/views`` keeping the directory layout intact.  The
script also loads embeddings from ``data/vectors`` if present to find similar
lots based on cosine similarity.  ``data/ontology/fields.json`` is consulted to
display table columns in a stable order.
"""

import math
import os
from pathlib import Path
import shutil
import subprocess
from datetime import datetime, timedelta, timezone

from jinja2 import Environment, FileSystemLoader
import gettext
from serde_utils import load_json
from lot_io import read_lots, get_seller, get_timestamp, iter_lot_files

try:
    from sklearn.neighbors import NearestNeighbors
    _has_sklearn = True
except Exception:
    _has_sklearn = False

from config_utils import load_config
from log_utils import get_logger, install_excepthook
from moderation import should_skip_message, should_skip_lot
from post_io import read_post

log = get_logger().bind(script=__file__)
install_excepthook(log)

LOTS_DIR = Path("data/lots")
VIEWS_DIR = Path("data/views")
TEMPLATES = Path("templates")
VEC_DIR = Path("data/vectors")
ONTOLOGY = Path("data/ontology/fields.json")
RAW_DIR = Path("data/raw")
LOCALE_DIR = Path("locale")
MEDIA_DIR = Path("data/media")

def _load_vectors() -> dict[str, list[float]]:
    """Return mapping of lot id to embedding vector."""
    if not VEC_DIR.exists():
        log.info("Vector directory missing", path=str(VEC_DIR))
        return {}
    data: dict[str, list[float]] = {}
    for path in VEC_DIR.rglob("*.json"):
        obj = load_json(path)
        if isinstance(obj, dict) and "id" in obj and "vec" in obj:
            data[obj["id"]] = obj["vec"]
        elif isinstance(obj, list):
            for item in obj:
                if isinstance(item, dict) and "id" in item and "vec" in item:
                    data[item["id"]] = item["vec"]
                else:
                    log.error("Bad vector entry", file=str(path))
        else:
            log.error("Failed to parse vector file", file=str(path))
    log.info("Loaded vectors", count=len(data))
    return data


def _cos_sim(a: list[float], b: list[float]) -> float:
    """Return cosine similarity between two vectors."""
    dot = sum(x * y for x, y in zip(a, b))
    na = math.sqrt(sum(x * x for x in a))
    nb = math.sqrt(sum(y * y for y in b))
    if na == 0 or nb == 0:
        return -1.0
    return dot / (na * nb)


def _format_vector(vec: list[float] | None) -> str | None:
    """Return compact JSON representation for ``vec``."""
    if vec is None:
        return None
    parts = [f"{v:.4f}".rstrip("0").rstrip(".") for v in vec]
    return "[" + ",".join(parts) + "]"


def _load_ontology() -> list[str]:
    if not ONTOLOGY.exists():
        return []
    data = load_json(ONTOLOGY)
    if not isinstance(data, dict):
        log.error("Bad ontology", path=str(ONTOLOGY))
        return []
    fields = sorted(data.keys())
    log.info("Loaded ontology", count=len(fields))
    return fields


def _compile_locale(lang: str) -> None:
    po = LOCALE_DIR / lang / 'LC_MESSAGES' / 'messages.po'
    mo = po.with_suffix('.mo')
    if not po.exists():
        return
    if not mo.exists() or po.stat().st_mtime > mo.stat().st_mtime:
        try:
            subprocess.run(['msgfmt', str(po), '-o', str(mo)], check=True)
            log.debug('Compiled translation', lang=lang)
        except Exception:
            log.exception('Failed to compile translation', lang=lang)


def _env_for_lang(lang: str) -> Environment:
    _compile_locale(lang)
    env = Environment(
        loader=FileSystemLoader(str(TEMPLATES)),
        extensions=['jinja2.ext.i18n'],
    )
    mo = LOCALE_DIR / lang / 'LC_MESSAGES' / 'messages.mo'
    try:
        trans = gettext.GNUTranslations(mo.open('rb'))
    except Exception:
        trans = gettext.NullTranslations()
    # Translation files use ``%(name)s`` placeholders generated by gettext,
    # so stick to the classic percent formatting style.  ``newstyle`` would
    # expect ``{name}`` placeholders which our .po files don't contain and
    # would trigger ``ValueError`` when rendering.
    env.install_gettext_translations(trans, newstyle=False)
    return env




def _iter_lots() -> list[dict]:
    """Return all lots ready for rendering."""
    lots = []
    # ``iter_lot_files`` keeps file ordering consistent with ``pending_embed.py``
    # so both scripts see the same data in the same order.
    for path in iter_lot_files(LOTS_DIR):
        data = read_lots(path)
        if not data:
            continue
        rel = path.relative_to(LOTS_DIR).with_suffix("")
        base = rel.name
        prefix = rel.parent
        for i, lot in enumerate(data):
            src = lot.get("source:path")
            meta: dict[str, str] | None = None
            text = ""
            if src:
                raw_path = RAW_DIR / src
                meta, text = read_post(raw_path)
                if should_skip_message(meta, text):
                    log.info(
                        "Skipping lot",
                        file=str(path),
                        reason="moderation",
                        source=str(src),
                    )
                    continue
            if should_skip_lot(lot):
                log.info(
                    "Skipping lot",
                    file=str(path),
                    reason="moderation",
                    source=str(src) if src else None,
                )
                continue
            lot["_file"] = path
            lot["_id"] = str(prefix / f"{base}-{i}") if prefix.parts else f"{base}-{i}"
            lots.append(lot)
    log.info("Loaded lots", count=len(lots))
    return lots


def _copy_images(lots: list[dict]) -> None:
    media_dst = VIEWS_DIR / "media"
    if media_dst.exists():
        shutil.rmtree(media_dst)
    for lot in lots:
        for rel in lot.get("files", []):
            src = MEDIA_DIR / rel
            if not src.exists():
                continue
            dst = media_dst / rel
            dst.parent.mkdir(parents=True, exist_ok=True)
            shutil.copy2(src, dst)


def build_page(
    lot: dict,
    similar: list[dict],
    more_user: list[dict],
    fields: list[str],
    langs: list[str],
    vector: list[float] | None,
) -> None:
    """Render ``lot`` into separate HTML files for every language."""
    for lang in langs:
        env = _env_for_lang(lang)
        images = []
        for rel in lot.get("files", []):
            p = MEDIA_DIR / rel
            cap = p.with_suffix(".caption.md")
            caption = cap.read_text(encoding="utf-8") if cap.exists() else ""
            images.append({"path": rel, "caption": caption})

        # Drop internal helper fields that are meaningless to end users.
        attrs = {
            k: v
            for k, v in lot.items()
            if k not in {"files"}
            and not k.startswith("title_")
            and not k.startswith("description_")
            and not k.startswith("source:")
            and not k.startswith("_")
            and v not in ("", None)
        }
        sorted_attrs = {k: attrs[k] for k in fields if k in attrs}
        for k in attrs:
            if k not in sorted_attrs:
                sorted_attrs[k] = attrs[k]

        ts = sorted_attrs.get("timestamp")
        dt = get_timestamp(lot)
        if ts and dt is None:
            del sorted_attrs["timestamp"]

        # Show the original message text for context if available.
        orig_text = ""
        src = lot.get("source:path")
        if src:
            _, orig_text = read_post(RAW_DIR / src)

        chat = lot.get("source:chat")
        mid = lot.get("source:message_id")
        tg_link = f"https://t.me/{chat}/{mid}" if chat and mid else ""

        template = env.get_template("lot.html")
        out = VIEWS_DIR / f"{lot['_id']}_{lang}.html"
        out.parent.mkdir(parents=True, exist_ok=True)

        page_similar = [
            {
                "link": os.path.relpath(VIEWS_DIR / f"{item['id']}_{lang}.html", out.parent),
                "title": item["title"],
                "thumb": item["thumb"],
            }
            for item in similar
        ]
        page_user = [
            {
                "link": os.path.relpath(VIEWS_DIR / f"{item['id']}_{lang}.html", out.parent),
                "title": item["title"],
                "thumb": item["thumb"],
            }
            for item in more_user
        ]
        static_prefix = os.path.relpath(VIEWS_DIR / "static", out.parent)
        media_prefix = os.path.relpath(VIEWS_DIR / "media", out.parent)
        home_link = os.path.relpath(VIEWS_DIR / f"index_{lang}.html", out.parent)
        page_basename = Path(lot['_id']).name
        breadcrumbs = [{"title": "Home", "link": home_link}]
        deal = lot.get("market:deal")
        if isinstance(deal, list):
            deal = deal[0] if deal else None
        if deal:
            cat_link = os.path.relpath(
                VIEWS_DIR / "deal" / f"{deal}_{lang}.html",
                out.parent,
            )
            breadcrumbs.append({"title": deal, "link": cat_link})
        breadcrumbs.append({"title": lot.get(f"title_{lang}") or lot['_id'], "link": None})
        vector_str = _format_vector(vector)
        out.write_text(
            template.render(
                title=lot.get(f"title_{lang}", "Lot"),
                lot=lot,
                images=images,
                attrs=sorted_attrs,
                orig_text=orig_text,
                description=lot.get(f"description_{lang}", ""),
                tg_link=tg_link,
                similar=page_similar,
                more_user=page_user,
                langs=langs,
                current_lang=lang,
                page_basename=page_basename,
                static_prefix=static_prefix,
                media_prefix=media_prefix,
                breadcrumbs=breadcrumbs,
                vector=vector_str,
            )
        )
        log.debug("Wrote", path=str(out))


def main() -> None:
    log.info("Building site")
    cfg = load_config()
    langs = getattr(cfg, "LANGS", ["en"])
    keep_days = getattr(cfg, "KEEP_DAYS", 7)
    envs = {lang: _env_for_lang(lang) for lang in langs}
    VIEWS_DIR.mkdir(parents=True, exist_ok=True)

    # Copy CSS and JS so the generated pages are standalone
    static_src = TEMPLATES / "static"
    static_dst = VIEWS_DIR / "static"
    if static_src.exists():
        if static_dst.exists():
            shutil.rmtree(static_dst)
        shutil.copytree(static_src, static_dst)
        log.debug("Copied static assets", src=str(static_src), dst=str(static_dst))

    log.debug("Loading ontology")
    fields = _load_ontology()
    log.debug("Loading vectors")
    vectors = _load_vectors()
    log.debug("Loading lots")
    lots = _iter_lots()
    _copy_images(lots)

    # Clean up mismatched data before working on vectors.
    lot_keys = {lot["_id"] for lot in lots}
    vec_keys = set(vectors)
    extra_vecs = vec_keys - lot_keys
    if extra_vecs:
        for key in extra_vecs:
            vectors.pop(key, None)
        log.debug("Dropped vectors without lots", count=len(extra_vecs))
    missing_vecs = lot_keys - vec_keys
    if missing_vecs:
        lots = [lot for lot in lots if lot["_id"] not in missing_vecs]
        log.debug("Dropped lots without vectors", count=len(missing_vecs))

    # Map each lot id to its embedding vector if available.
    id_to_vec = {lot["_id"]: vectors.get(lot["_id"]) for lot in lots}

    log.info("Computing similar lots", count=len(lots))
    sim_map: dict[str, list[dict]] = {}

    vec_ids = [lot["_id"] for lot in lots if id_to_vec.get(lot["_id"])]
    if _has_sklearn and vec_ids:
        matrix = [id_to_vec[i] for i in vec_ids]
        # ``kneighbors`` raises when ``n_neighbors`` exceeds the number of
        # vectors, so keep the value within bounds.
        k = min(7, len(matrix))
        nn = NearestNeighbors(n_neighbors=k, metric="cosine")
        nn.fit(matrix)
        dists, idxs = nn.kneighbors(matrix)
        idx_to_id = {i: vec_ids[i] for i in range(len(vec_ids))}
        lookup = {lot["_id"]: lot for lot in lots}
        for i, lot_id in enumerate(vec_ids):
            items = []
            for dist, other_idx in zip(dists[i][1:], idxs[i][1:]):
                other = lookup[idx_to_id[other_idx]]
                title = other.get("title_en") or next(
                    (other.get(f"title_{l}") for l in langs if other.get(f"title_{l}")),
                    other.get("_id"),
                )
                files = other.get("files") or []
                thumb = files[0] if files else ""
                items.append({"id": other["_id"], "title": title, "thumb": thumb})
            sim_map[lot_id] = items
    else:
        for lot in lots:
            vec = id_to_vec.get(lot["_id"])
            if not vec:
                sim_map[lot["_id"]] = []
                continue
            scores = []
            for other in lots:
                if other is lot:
                    continue
                ov = id_to_vec.get(other["_id"])
                if not ov:
                    continue
                scores.append((_cos_sim(vec, ov), other))
            scores.sort(key=lambda x: x[0], reverse=True)
            items = []
            for score, other in scores[:6]:
                title = other.get("title_en") or next(
                    (other.get(f"title_{l}") for l in langs if other.get(f"title_{l}")),
                    other.get("_id"),
                )
                files = other.get("files") or []
                thumb = files[0] if files else ""
                items.append({"id": other["_id"], "title": title, "thumb": thumb})
            sim_map[lot["_id"]] = items

    # Collect lots by Telegram user for "more by this user" section.
    user_map: dict[str, list[dict]] = {}
    for lot in lots:
        user = (
            lot.get("contact:telegram")
            or lot.get("source:author:telegram")
            or lot.get("source:author:name")
        )
        if isinstance(user, list):
            log.debug("Multiple telegram users", id=lot.get("_id"), value=user)
            user = user[0] if user else None
        if user is not None:
            user_map.setdefault(str(user), []).append(lot)

    more_user_map: dict[str, list[dict]] = {}
    for user, user_lots in user_map.items():
        for lot in user_lots:
            others = [o for o in user_lots if o is not lot]
            scores = []
            vec = id_to_vec.get(lot["_id"])
            for other in others:
                ov = id_to_vec.get(other["_id"])
                if vec and ov:
                    scores.append((_cos_sim(vec, ov), other))
                else:
                    scores.append((0.0, other))
            scores.sort(key=lambda x: x[0], reverse=True)
            items = []
            for score, other in scores[:20]:
                title = other.get("title_en") or next(
                    (other.get(f"title_{l}") for l in langs if other.get(f"title_{l}")),
                    other.get("_id"),
                )
                files = other.get("files") or []
                thumb = files[0] if files else ""
                items.append({"id": other["_id"], "title": title, "thumb": thumb})
            more_user_map[lot["_id"]] = items

    # ``datetime.utcnow`` returns a naive object which breaks comparisons with
    # timezone-aware timestamps coming from lots.  Normalize everything to UTC.
    now = datetime.now(timezone.utc)
    recent_cutoff = now - timedelta(days=keep_days)
    recent = []
    categories: dict[str, list[dict]] = {}
    category_stats: dict[str, dict] = {}
    for lot in lots:
        dt = get_timestamp(lot)
        deal = lot.get("market:deal", "misc")
        if not isinstance(deal, str):
            log.debug("Non-string deal", id=lot.get("_id"), value=deal)
            if isinstance(deal, list) and deal:
                deal = deal[0]
            else:
                deal = str(deal)
        categories.setdefault(deal, []).append(lot)
        stat = category_stats.setdefault(deal, {"recent": 0, "users": set()})
        user = lot.get("contact:telegram")
        if isinstance(user, list):
            log.debug("Multiple telegram users", id=lot.get("_id"), value=user)
            user = user[0] if user else None
        if user:
            stat["users"].add(str(user))
        if dt and dt >= recent_cutoff:
            titles = {lang: lot.get(f"title_{lang}") for lang in langs}
            seller = get_seller(lot)
            stat["recent"] += 1
            recent.append(
                {
                    "id": lot["_id"],
                    "titles": titles,
                    "dt": dt,
                    "price": lot.get("price"),
                    "seller": seller,
                }
            )

    for lot in lots:
        log.debug("Rendering", id=lot["_id"])
        build_page(
            lot,
            sim_map.get(lot["_id"], []),
            more_user_map.get(lot["_id"], []),
            fields,
            langs,
            id_to_vec.get(lot["_id"]),
        )

    log.debug("Writing category pages")
    cat_tpls = {lang: envs[lang].get_template("category.html") for lang in langs}
    cat_dir = VIEWS_DIR / "deal"
    cat_dir.mkdir(parents=True, exist_ok=True)
    for deal, lot_list in categories.items():
        lot_list_sorted = sorted(
            lot_list,
            key=lambda x: get_timestamp(x) or datetime.min,
            reverse=True,
        )
        for lang in langs:
            items_lang = []
            for lot in lot_list_sorted:
                title = lot.get(f"title_{lang}") or next(
                    (lot.get(f"title_{l}") for l in langs if lot.get(f"title_{l}")),
                    lot.get("_id"),
                )
                seller = get_seller(lot)
                dt = get_timestamp(lot)
                items_lang.append(
                    {
                        "link": os.path.relpath(
                            VIEWS_DIR / f"{lot['_id']}_{lang}.html",
                            cat_dir,
                        ),
                        "title": title,
                        "dt": dt,
                        "price": lot.get("price"),
                        "seller": seller,
                        "id": lot["_id"],
                        "vec": _format_vector(id_to_vec.get(lot["_id"])),
                    }
                )
            out = cat_dir / f"{deal}_{lang}.html"
            breadcrumbs = [
                {"title": "Home", "link": os.path.relpath(VIEWS_DIR / f"index_{lang}.html", cat_dir)},
                {"title": deal, "link": None},
            ]
            out.write_text(
                cat_tpls[lang].render(
                    deal=deal,
                    items=items_lang,
                    langs=langs,
                    current_lang=lang,
                    page_basename=deal,
                    title=deal,
                    static_prefix=os.path.relpath(VIEWS_DIR / "static", cat_dir),
                    breadcrumbs=breadcrumbs,
                )
            )
            log.debug("Wrote", path=str(out))

    recent.sort(key=lambda x: x.get("dt") or datetime.min.replace(tzinfo=timezone.utc), reverse=True)

    log.debug("Writing index pages")
    index_tpls = {lang: envs[lang].get_template("index.html") for lang in langs}
    for lang in langs:
        cats_lang = []
        for deal, stat in category_stats.items():
            cats_lang.append(
                {
                    "link": os.path.relpath(cat_dir / f"{deal}_{lang}.html", VIEWS_DIR),
                    "deal": deal,
                    "recent": stat["recent"],
                    "users": len(stat["users"]),
                }
            )
        out = VIEWS_DIR / f"index_{lang}.html"
        breadcrumbs = [{"title": "Home", "link": f"index_{lang}.html"}]
        out.write_text(
            index_tpls[lang].render(
                categories=cats_lang,
                langs=langs,
                current_lang=lang,
                page_basename="index",
                title="Index",
                static_prefix=os.path.relpath(VIEWS_DIR / "static", VIEWS_DIR),
                breadcrumbs=breadcrumbs,
                keep_days=keep_days,
            )
        )
        log.debug("Wrote", path=str(out))
    if langs:
        default = VIEWS_DIR / "index.html"
        src = VIEWS_DIR / f"index_{langs[0]}.html"
        default.write_text(src.read_text())
        log.debug("Wrote", path=str(default))
    log.info("Site build complete")


if __name__ == "__main__":
    main()
